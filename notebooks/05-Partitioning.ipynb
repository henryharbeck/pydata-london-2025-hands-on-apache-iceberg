{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380d222d-b0a6-440b-95c4-bb6a3c8370e5",
   "metadata": {},
   "source": [
    "# Partitioning\n",
    "\n",
    "Iceberg (and other lakehouses) don't provide indexes that you may be used to from a more traditional datawarehouse, but they do provide a concept of partitioning, which serves a similar purpose. \n",
    "\n",
    "Partitioning refers to structuring the way the files are saved to disk in order to co-locate ranges of values. This makes it more likely that the query engine only has to read a few files to get all the requested data instead of all of them.\n",
    "\n",
    "If you haven't noticed the theme yet, it's all about eliminating as much disk I/O as possible. The less files we have to scan, the more performant our query is!\n",
    "\n",
    "Iceberg implements what they call *Hidden Partitioning*, and let's digress a little bit to the past to understand what that means.\n",
    "\n",
    "Hive implemented *Explicit partitioning*, where the user needs to be aware of the partitioning and explicitly use when reading and writing.\n",
    "\n",
    "```{figure} images/hive_partitioning.png\n",
    ":alt: Hive-style partitioning\n",
    ":align: center\n",
    ":figwidth: image\n",
    "\n",
    "Hive-style partitioning\n",
    "```\n",
    "\n",
    "The main issue with Hive-style partitioning is that it is explicit.\n",
    "Given this partitioning scheme, if I wanted to query a range 2024-01-01 <=> 2024-02-28 I might want to write this query\n",
    "\n",
    "```sql\n",
    "SELECT * FROM reviews WHERE review_date between '2024-01-01' AND '2024-02-28'\n",
    "```\n",
    "\n",
    "This query would not use the index, as Hive is explicitly expecting a year, month and date filter.\n",
    "\n",
    "```sql\n",
    "SELECT * from reviews where year = 2024 AND (month = 1 OR month = 2) AND DAY BETWEEN 1 and 31\n",
    "```\n",
    "\n",
    "Iceberg hides this complexity away from the user, hence **Hidden Partitioning**\n",
    "\n",
    "We could have defined our partitioning when we created the table, but like much of data engineering, we often realize later that we needed it. Predicting query patterns up-front is a big ask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c357fbc-7589-4d8f-a236-b45fbc597be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import house_prices_schema\n",
    "from utils import read_house_prices, catalog, engine, get_iceberg_metadata, fs\n",
    "from IPython.display import JSON\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f640d26-9258-41e6-b4f3-6e0ecb98273d",
   "metadata": {},
   "source": [
    "Let's reset everything to start from a clean slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa1c8c2-5960-4509-bd5f-b370c6c6a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.drop_table(\"housing.staging_prices\", purge_requested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43647f8-c558-4173-b976-b75e7de75c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "house_prices_t = catalog.create_table_if_not_exists(\n",
    "    \"housing.staging_prices\",\n",
    "    schema=house_prices_schema,\n",
    "    location=\"s3://warehouse/staging\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b5bca-91f7-45f9-b013-acc1c4309958",
   "metadata": {},
   "source": [
    "## Hidden Partitioning\n",
    "\n",
    "Iceberg defines a number of supported `transforms` - functions that Iceberg will use to map a query onto a partition. Dates are pretty common in warehouses, so Year, Month, Day transfomrs enable intelligent date-based partitioning. For keys and identifiers, Bucket and Truncate are used to ensure a distributed write pattern. \n",
    "\n",
    "In this case, we know we're interested in date-based queries, and since we don't have a lot of daily activity, partitioning by month sounds like a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1865955-b012-47f2-8806-d5b3ad74168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.transforms import MonthTransform, YearTransform\n",
    "\n",
    "with house_prices_t.update_spec() as spec:\n",
    "    spec.add_field(\"date_of_transfer\", MonthTransform(), \"month_date_of_transfer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91ea48-357f-4079-acd6-a080055e07be",
   "metadata": {},
   "source": [
    "Let's have a look at the metadata file after the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f0b003-2538-4f8e-9038-693b4fd53bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "current-schema-id": 0,
       "default-sort-order-id": 0,
       "default-spec-id": 1,
       "format-version": 2,
       "last-column-id": 16,
       "last-partition-id": 1000,
       "last-sequence-number": 0,
       "last-updated-ms": 1749199870640,
       "location": "s3://warehouse/staging",
       "metadata-log": [
        {
         "metadata-file": "s3://warehouse/staging/metadata/00000-0197446f-c0b6-78f2-9be9-fd3ddfcf73fc.gz.metadata.json",
         "timestamp-ms": 1749199863990
        }
       ],
       "partition-specs": [
        {
         "fields": [],
         "spec-id": 0
        },
        {
         "fields": [
          {
           "field-id": 1000,
           "name": "month_date_of_transfer",
           "source-id": 3,
           "transform": "month"
          }
         ],
         "spec-id": 1
        }
       ],
       "refs": {},
       "schemas": [
        {
         "fields": [
          {
           "doc": "A reference number which is generated automatically recording each published sale. The number is unique and will change each time a sale is recorded.",
           "id": 1,
           "name": "transaction_id",
           "required": true,
           "type": "string"
          },
          {
           "doc": "Sale price stated on the transfer deed.",
           "id": 2,
           "name": "price",
           "required": true,
           "type": "int"
          },
          {
           "doc": "Date when the sale was completed, as stated on the transfer deed.",
           "id": 3,
           "name": "date_of_transfer",
           "required": true,
           "type": "date"
          },
          {
           "doc": "This is the postcode used at the time of the original transaction. Postcodes can be reallocated and these changes are not reflected in the Price Paid Dataset.",
           "id": 4,
           "name": "postcode",
           "required": true,
           "type": "string"
          },
          {
           "doc": "D = Detached, S = Semi-Detached, T = Terraced, F = Flats/Maisonettes, O = Other",
           "id": 5,
           "name": "property_type",
           "required": true,
           "type": "string"
          },
          {
           "doc": "Indicates the age of the property and applies to all price paid transactions, residential and non-residential. Y = a newly built property, N = an established residential building",
           "id": 6,
           "name": "new_property",
           "required": true,
           "type": "string"
          },
          {
           "doc": "Relates to the tenure: F = Freehold, L= Leasehold etc. Note that HM Land Registry does not record leases of 7 years or less in the Price Paid Dataset.",
           "id": 7,
           "name": "duration",
           "required": true,
           "type": "string"
          },
          {
           "doc": "Primary Addressable Object Name. Typically the house number or name",
           "id": 8,
           "name": "paon",
           "required": false,
           "type": "string"
          },
          {
           "doc": "Secondary Addressable Object Name. Where a property has been divided into separate units (for example, flats), the PAON (above) will identify the building and a SAON will be specified that identifies the separate unit/flat.",
           "id": 9,
           "name": "saon",
           "required": false,
           "type": "string"
          },
          {
           "id": 10,
           "name": "street",
           "required": false,
           "type": "string"
          },
          {
           "id": 11,
           "name": "locality",
           "required": false,
           "type": "string"
          },
          {
           "id": 12,
           "name": "town",
           "required": false,
           "type": "string"
          },
          {
           "id": 13,
           "name": "district",
           "required": false,
           "type": "string"
          },
          {
           "id": 14,
           "name": "county",
           "required": false,
           "type": "string"
          },
          {
           "doc": "Indicates the type of Price Paid transaction. A = Standard Price Paid entry, includes single residential property sold for value. B = Additional Price Paid entry including transfers under a power of sale/repossessions, buy-to-lets (where they can be identified by a Mortgage), transfers to non-private individuals and sales where the property type is classed as ‘Other’.",
           "id": 15,
           "name": "ppd_category_type",
           "required": false,
           "type": "string"
          },
          {
           "doc": "Indicates additions, changes and deletions to the records. A = Addition C = Change D = Delete",
           "id": 16,
           "name": "record_status",
           "required": false,
           "type": "string"
          }
         ],
         "identifier-field-ids": [
          1
         ],
         "schema-id": 0,
         "type": "struct"
        }
       ],
       "sort-orders": [
        {
         "fields": [],
         "order-id": 0
        }
       ],
       "table-uuid": "0197446f-c0b5-7980-84e2-85bab3a94592"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(get_iceberg_metadata(fs, house_prices_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b6134-a7b3-4dcf-8d63-c15db2281ef1",
   "metadata": {},
   "source": [
    "Now that we've setup some partitioning - let's load in our data to see what that looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026e0d61-102e-47e3-bed0-19020af8eba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/house_prices/pp-2015.csv'),\n",
       " PosixPath('data/house_prices/pp-2016.csv'),\n",
       " PosixPath('data/house_prices/pp-2017.csv'),\n",
       " PosixPath('data/house_prices/pp-2018.csv'),\n",
       " PosixPath('data/house_prices/pp-2019.csv'),\n",
       " PosixPath('data/house_prices/pp-2020.csv'),\n",
       " PosixPath('data/house_prices/pp-2021.csv'),\n",
       " PosixPath('data/house_prices/pp-2022.csv'),\n",
       " PosixPath('data/house_prices/pp-2023.csv'),\n",
       " PosixPath('data/house_prices/pp-2024.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "files_to_load = sorted(list(pathlib.Path(\"data/house_prices/\").glob(\"*.csv\")))\n",
    "files_to_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5c26e-f742-41da-bc7d-d6e5bc6f56e4",
   "metadata": {},
   "source": [
    "We could imagine that for each monthly load, we would want to generate a tag to be easily able to roll back to a given load, so let's do that for fun :).\n",
    "\n",
    "Let's start by reading in the first file and loading it to our Iceberg table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c547e30-3521-4fef-ac51-d24be8ae2f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into Iceberg\n",
    "df = read_house_prices(files_to_load[0]).to_arrow().cast(house_prices_schema.as_arrow())\n",
    "house_prices_t.append(df)\n",
    "\n",
    "year = files_to_load[0].name[3:7]\n",
    "# Tag the new snapshot - retain it for a month\n",
    "current_snapshot = house_prices_t.current_snapshot().snapshot_id\n",
    "house_prices_t.manage_snapshots().create_tag(\n",
    "    current_snapshot, f\"{year}_load\", max_ref_age_ms=2629746000\n",
    ").commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f782290-f1ac-4779-9607-c35c4fa4a8b2",
   "metadata": {},
   "source": [
    "Let's have a look at what is happening in the physical storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e494e1f-3c03-4156-98eb-d74b56854153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warehouse/staging/data/month_date_of_transfer=2015-01',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-02',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-03',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-04',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-05',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-06',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-07',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-08',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-09',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-10',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-11',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-12']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(f\"{house_prices_t.location()}/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2eb2c-bd81-4456-a408-4aaee48a4e06",
   "metadata": {},
   "source": [
    "The data is now physically partitioned by year-month, and we can now use it without having to know anything about the partitioning. To show how query engines can take advantage of this, let's compare two SQL statements in Trino. \n",
    "\n",
    "Looking at the Trino query plan, we can see that the first query is scanning twice the number of rows compared to the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46cec883-9d1f-4145-8855-2b455c980219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trino version: 475\n",
      "Queued: 795.06us, Analysis: 35.44ms, Planning: 57.33ms, Execution: 299.54ms\n",
      "Fragment 1 [SINGLE]\n",
      "    CPU: 4.23ms, Scheduled: 10.28ms, Blocked 427.47ms (Input: 349.75ms, Output: 0.00ns), Input: 12 rows (60B); per task: avg.: 12.00 std.dev.: 0.00, Output: 1 row (5B)\n",
      "    Peak Memory: 304B, Tasks count: 1; per task: max: 304B\n",
      "    Output layout: [max]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = FINAL]\n",
      "    │   Layout: [max:integer]\n",
      "    │   Estimates: {rows: 1 (5B), cpu: 2.41M, memory: 5B, network: 0B}\n",
      "    │   CPU: 2.00ms (0.74%), Scheduled: 3.00ms (0.39%), Blocked: 0.00ns (0.00%), Output: 1 row (5B)\n",
      "    │   Input avg.: 12.00 rows, Input std.dev.: 0.00%\n",
      "    │   max := max(max_0)\n",
      "    └─ LocalExchange[partitioning = SINGLE]\n",
      "       │   Layout: [max_0:integer]\n",
      "       │   Estimates: {rows: 505404 (2.41MB), cpu: 0, memory: 0B, network: 0B}\n",
      "       │   CPU: 0.00ns (0.00%), Scheduled: 2.00ms (0.26%), Blocked: 81.00ms (18.79%), Output: 12 rows (60B)\n",
      "       │   Input avg.: 3.00 rows, Input std.dev.: 102.74%\n",
      "       └─ RemoteSource[sourceFragmentIds = [2]]\n",
      "              Layout: [max_0:integer]\n",
      "              CPU: 1.00ms (0.37%), Scheduled: 4.00ms (0.52%), Blocked: 350.00ms (81.21%), Output: 12 rows (60B)\n",
      "              Input avg.: 3.00 rows, Input std.dev.: 102.74%\n",
      "\n",
      "Fragment 2 [SOURCE]\n",
      "    CPU: 269.47ms, Scheduled: 756.77ms, Blocked 0.00ns (Input: 0.00ns, Output: 0.00ns), Input: 1010808 rows (8.90MB); per task: avg.: 1010808.00 std.dev.: 0.00, Output: 12 rows (60B)\n",
      "    Peak Memory: 1.21kB, Tasks count: 1; per task: max: 1.21kB\n",
      "    Total split distribution time: 10.72ms\n",
      "    Output layout: [max_0]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = PARTIAL]\n",
      "    │   Layout: [max_0:integer]\n",
      "    │   Estimates: {rows: 505404 (2.41MB), cpu: ?, memory: ?, network: ?}\n",
      "    │   CPU: 10.00ms (3.69%), Scheduled: 27.00ms (3.53%), Blocked: 0.00ns (0.00%), Output: 12 rows (60B)\n",
      "    │   Input avg.: 902.83 rows, Input std.dev.: 18.79%\n",
      "    │   max_0 := max(price)\n",
      "    └─ ScanFilterProject[table = lakekeeper:housing.staging_prices$data@6919326858160025325, filterPredicate = (county = varchar 'WORCESTERSHIRE')]\n",
      "           Layout: [price:integer]\n",
      "           Estimates: {rows: 1010808 (4.82MB), cpu: 11.56M, memory: 0B, network: 0B}/{rows: 505404 (2.41MB), cpu: 11.56M, memory: 0B, network: 0B}/{rows: 505404 (2.41MB), cpu: 2.41M, memory: 0B, network: 0B}\n",
      "           CPU: 258.00ms (95.20%), Scheduled: 729.00ms (95.29%), Blocked: 0.00ns (0.00%), Output: 10834 rows (52.90kB)\n",
      "           Input avg.: 84234.00 rows, Input std.dev.: 15.25%\n",
      "           county := 14:county:varchar\n",
      "           price := 2:price:integer\n",
      "           Input: 1010808 rows (8.90MB), Filtered: 98.93%, Physical input: 21.94MB, Physical input time: 11.50ms, Splits: 12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No partition on 'county'\n",
    "print(\n",
    "    pl.read_database(\n",
    "        \"EXPLAIN ANALYZE SELECT max(price) as max_price from housing.staging_prices where county = 'WORCESTERSHIRE'\",\n",
    "        engine,\n",
    "    ).item(0, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e47ea77-de1e-4e80-92e5-64e54f63d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trino version: 475\n",
      "Queued: 363.33us, Analysis: 56.12ms, Planning: 47.09ms, Execution: 265.00ms\n",
      "Fragment 1 [SINGLE]\n",
      "    CPU: 2.10ms, Scheduled: 2.42ms, Blocked 472.89ms (Input: 373.65ms, Output: 0.00ns), Input: 6 rows (30B); per task: avg.: 6.00 std.dev.: 0.00, Output: 1 row (5B)\n",
      "    Peak Memory: 304B, Tasks count: 1; per task: max: 304B\n",
      "    Output layout: [max]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = FINAL]\n",
      "    │   Layout: [max:integer]\n",
      "    │   Estimates: {rows: 1 (5B), cpu: 2.12M, memory: 5B, network: 0B}\n",
      "    │   CPU: 0.00ns (0.00%), Scheduled: 0.00ns (0.00%), Blocked: 0.00ns (0.00%), Output: 1 row (5B)\n",
      "    │   Input avg.: 6.00 rows, Input std.dev.: 0.00%\n",
      "    │   max := max(max_0)\n",
      "    └─ LocalExchange[partitioning = SINGLE]\n",
      "       │   Layout: [max_0:integer]\n",
      "       │   Estimates: {rows: 444598 (2.12MB), cpu: 0, memory: 0B, network: 0B}\n",
      "       │   CPU: 0.00ns (0.00%), Scheduled: 0.00ns (0.00%), Blocked: 91.00ms (19.57%), Output: 6 rows (30B)\n",
      "       │   Input avg.: 1.50 rows, Input std.dev.: 74.54%\n",
      "       └─ RemoteSource[sourceFragmentIds = [2]]\n",
      "              Layout: [max_0:integer]\n",
      "              CPU: 0.00ns (0.00%), Scheduled: 0.00ns (0.00%), Blocked: 374.00ms (80.43%), Output: 6 rows (30B)\n",
      "              Input avg.: 1.50 rows, Input std.dev.: 74.54%\n",
      "\n",
      "Fragment 2 [SOURCE]\n",
      "    CPU: 207.10ms, Scheduled: 383.15ms, Blocked 0.00ns (Input: 0.00ns, Output: 0.00ns), Input: 444598 rows (2.12MB); per task: avg.: 444598.00 std.dev.: 0.00, Output: 6 rows (30B)\n",
      "    Peak Memory: 12.08MB, Tasks count: 1; per task: max: 12.08MB\n",
      "    Total split distribution time: 7.33ms\n",
      "    Output layout: [max_0]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = PARTIAL]\n",
      "    │   Layout: [max_0:integer]\n",
      "    │   Estimates: {rows: 444598 (2.12MB), cpu: ?, memory: ?, network: ?}\n",
      "    │   CPU: 179.00ms (86.89%), Scheduled: 307.00ms (80.37%), Blocked: 0.00ns (0.00%), Output: 6 rows (30B)\n",
      "    │   Input avg.: 74099.67 rows, Input std.dev.: 13.99%\n",
      "    │   max_0 := max(price)\n",
      "    └─ TableScan[table = lakekeeper:housing.staging_prices$data@6919326858160025325 constraint on [date_of_transfer]]\n",
      "           Layout: [price:integer]\n",
      "           Estimates: {rows: 444598 (2.12MB), cpu: 2.12M, memory: 0B, network: 0B}\n",
      "           CPU: 27.00ms (13.11%), Scheduled: 75.00ms (19.63%), Blocked: 0.00ns (0.00%), Output: 444598 rows (2.12MB)\n",
      "           Input avg.: 74099.67 rows, Input std.dev.: 13.99%\n",
      "           price := 2:price:integer\n",
      "           3:date_of_transfer:date\n",
      "               :: [[2015-01-01, 2015-06-30]]\n",
      "           Input: 444598 rows (2.12MB), Physical input: 11.37MB, Physical input time: 39.05ms, Splits: 6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Partition on 'date_of_transfer'\n",
    "print(\n",
    "    pl.read_database(\n",
    "        \"EXPLAIN ANALYZE SELECT max(price) as max_price from housing.staging_prices where date_of_transfer between DATE '2015-01-01' AND DATE '2015-06-30'\",\n",
    "        engine,\n",
    "    ).item(0, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6e6a6-36e6-43a5-b645-6e8972026d2b",
   "metadata": {},
   "source": [
    "But how big were the files we're scanning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b92b8d-a222-4d6f-9a9f-f527b0ae3b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Key': 'warehouse/staging/data/month_date_of_transfer=2015-01/00000-4-49b901b0-d684-4657-9205-7953c9306936.parquet',\n",
       "  'LastModified': datetime.datetime(2025, 6, 6, 8, 52, 14, 325000, tzinfo=tzlocal()),\n",
       "  'ETag': '\"e8ef58c3cf2e96520f4cd18e1674890d-1\"',\n",
       "  'Size': 2696479,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'type': 'file',\n",
       "  'size': 2696479,\n",
       "  'name': 'warehouse/staging/data/month_date_of_transfer=2015-01/00000-4-49b901b0-d684-4657-9205-7953c9306936.parquet'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"warehouse/staging/data/month_date_of_transfer=2015-01\", detail=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad7ddc-dad6-4f37-8924-a3cf14eba09f",
   "metadata": {},
   "source": [
    "Around 2.7 Mb - that's not very big at all - while there is no strict guidelines, consensus is that the Parquet files should be somewhere between 128 MB and 1 GB **uncompressed**, depending on use case, as the overhead of reading many small files adds up quick. \n",
    "\n",
    "Luckily, we can quickly change our partitioning, without having to rewrite our existing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ab2ebc-3ff1-4938-8b7d-bb62533bb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with house_prices_t.update_spec() as spec:\n",
    "    spec.remove_field(\"month_date_of_transfer\")\n",
    "    spec.add_field(\"date_of_transfer\", YearTransform(), \"year_date_of_transfer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d478f97-3f5d-4a77-9cb7-9ce50647ad73",
   "metadata": {},
   "source": [
    "Changing partitioning doesn't alter existing files, it only affects future files. To demonstrate let's load the next file to see the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b8edb58-9c36-498c-8df4-7d6795b88a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into Iceberg\n",
    "df = read_house_prices(files_to_load[1]).to_arrow().cast(house_prices_schema.as_arrow())\n",
    "house_prices_t.append(df)\n",
    "\n",
    "year = files_to_load[1].name[3:7]\n",
    "# Tag the new snapshot - retain it for a month\n",
    "current_snapshot = house_prices_t.current_snapshot().snapshot_id\n",
    "house_prices_t.manage_snapshots().create_tag(\n",
    "    current_snapshot, f\"{year}_load\", max_ref_age_ms=2629746000\n",
    ").commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d4de9-5ecc-438d-b69b-ba1f20376102",
   "metadata": {},
   "source": [
    "Let's look at the file structure now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04fd134-d979-488a-872d-b468261359d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warehouse/staging/data/month_date_of_transfer=2015-01',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-02',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-03',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-04',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-05',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-06',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-07',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-08',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-09',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-10',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-11',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-12',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2016']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(f\"{house_prices_t.location()}/data\", refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5122be8-3769-4586-a627-2278aca84fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Key': 'warehouse/staging/data/year_date_of_transfer=2016/00000-0-8203efbb-3f38-4952-9346-6cc1eb908d15.parquet',\n",
       "  'LastModified': datetime.datetime(2025, 6, 6, 8, 55, 12, 675000, tzinfo=tzlocal()),\n",
       "  'ETag': '\"0d0fe2f7d88f943e36a9bcc02367685a-3\"',\n",
       "  'Size': 23232332,\n",
       "  'StorageClass': 'STANDARD',\n",
       "  'type': 'file',\n",
       "  'size': 23232332,\n",
       "  'name': 'warehouse/staging/data/year_date_of_transfer=2016/00000-0-8203efbb-3f38-4952-9346-6cc1eb908d15.parquet'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"warehouse/staging/data/year_date_of_transfer=2016\", detail=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf12d6-e3d0-46b4-96b6-ee60257b2059",
   "metadata": {},
   "source": [
    "Around 23 Mb - better, parquet compresses well after all so this is closer to optimal size. We'll keep this and load the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d6ece1-365c-4bac-b5a2-e7797acab681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending pp-2017.csv - 1,067,186 rows\n",
      "Tagged: 2017_load\n",
      "Appending pp-2018.csv - 1,037,178 rows\n",
      "Tagged: 2018_load\n",
      "Appending pp-2019.csv - 1,011,415 rows\n",
      "Tagged: 2019_load\n",
      "Appending pp-2020.csv - 895,643 rows\n",
      "Tagged: 2020_load\n",
      "Appending pp-2021.csv - 1,277,810 rows\n",
      "Tagged: 2021_load\n",
      "Appending pp-2022.csv - 1,069,660 rows\n",
      "Tagged: 2022_load\n",
      "Appending pp-2023.csv - 848,435 rows\n",
      "Tagged: 2023_load\n",
      "Appending pp-2024.csv - 766,641 rows\n",
      "Tagged: 2024_load\n"
     ]
    }
   ],
   "source": [
    "for filename in files_to_load[2:]:\n",
    "    # Grab the year from the filename\n",
    "    year = filename.name[3:7]\n",
    "    # Read in the CSV\n",
    "    df = read_house_prices(filename).to_arrow().cast(house_prices_schema.as_arrow())\n",
    "    print(f\"Appending {filename.name} - {len(df):,} rows\")\n",
    "    # Write to Iceberg\n",
    "    house_prices_t.append(df)\n",
    "    # Get the new snapshot id\n",
    "    current_snapshot = house_prices_t.current_snapshot().snapshot_id\n",
    "    # Tag the new snapshot - retain it for a month\n",
    "    house_prices_t.manage_snapshots().create_tag(\n",
    "        current_snapshot, f\"{year}_load\", max_ref_age_ms=2629746000\n",
    "    ).commit()\n",
    "    print(f\"Tagged: {year}_load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12620a83-f926-47b9-9634-5571b0e91fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warehouse/staging/data/month_date_of_transfer=2015-01',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-02',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-03',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-04',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-05',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-06',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-07',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-08',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-09',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-10',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-11',\n",
       " 'warehouse/staging/data/month_date_of_transfer=2015-12',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2016',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2017',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2018',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2019',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2020',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2021',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2022',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2023',\n",
       " 'warehouse/staging/data/year_date_of_transfer=2024']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(f\"{house_prices_t.location()}/data\", refresh=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99f036ba-cd7e-431a-9124-ee55767ecfc1",
   "metadata": {},
   "source": [
    "Now Iceberg has two different partitions to keep track of, so it will split the partition planning across the two partitions\n",
    "\n",
    "![Partition Spec Evolution](images/partition_spec_evolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f64ac-ef7e-43ef-9a15-0440f5cd19ab",
   "metadata": {},
   "source": [
    "Let's re-examine our query plans to see if we can spot the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "233f373c-6624-498f-bc69-2924c3905cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trino version: 475\n",
      "Queued: 908.67us, Analysis: 108.34ms, Planning: 79.41ms, Execution: 431.94ms\n",
      "Fragment 1 [SINGLE]\n",
      "    CPU: 4.37ms, Scheduled: 6.79ms, Blocked 1.02s (Input: 807.85ms, Output: 0.00ns), Input: 24 rows (120B); per task: avg.: 24.00 std.dev.: 0.00, Output: 1 row (5B)\n",
      "    Peak Memory: 304B, Tasks count: 1; per task: max: 613B\n",
      "    Output layout: [max]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = FINAL]\n",
      "    │   Layout: [max:integer]\n",
      "    │   Estimates: {rows: 1 (5B), cpu: 23.92M, memory: 5B, network: 0B}\n",
      "    │   CPU: 1.00ms (0.16%), Scheduled: 1.00ms (0.05%), Blocked: 0.00ns (0.00%), Output: 1 row (5B)\n",
      "    │   Input avg.: 24.00 rows, Input std.dev.: 0.00%\n",
      "    │   max := max(max_0)\n",
      "    └─ LocalExchange[partitioning = SINGLE]\n",
      "       │   Layout: [max_0:integer]\n",
      "       │   Estimates: {rows: 5015418 (23.92MB), cpu: 0, memory: 0B, network: 0B}\n",
      "       │   CPU: 0.00ns (0.00%), Scheduled: 1.00ms (0.05%), Blocked: 183.00ms (18.47%), Output: 24 rows (120B)\n",
      "       │   Input avg.: 6.00 rows, Input std.dev.: 35.36%\n",
      "       └─ RemoteSource[sourceFragmentIds = [2]]\n",
      "              Layout: [max_0:integer]\n",
      "              CPU: 1.00ms (0.16%), Scheduled: 3.00ms (0.14%), Blocked: 808.00ms (81.53%), Output: 24 rows (120B)\n",
      "              Input avg.: 6.00 rows, Input std.dev.: 35.36%\n",
      "\n",
      "Fragment 2 [SOURCE]\n",
      "    CPU: 641.43ms, Scheduled: 2.16s, Blocked 0.00ns (Input: 0.00ns, Output: 0.00ns), Input: 10009751 rows (81.81MB); per task: avg.: 10009751.00 std.dev.: 0.00, Output: 24 rows (120B)\n",
      "    Peak Memory: 1.51kB, Tasks count: 1; per task: max: 21.26MB\n",
      "    Total split distribution time: 19.56ms\n",
      "    Output layout: [max_0]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = PARTIAL]\n",
      "    │   Layout: [max_0:integer]\n",
      "    │   Estimates: {rows: 5015418 (23.92MB), cpu: ?, memory: ?, network: ?}\n",
      "    │   CPU: 11.00ms (1.72%), Scheduled: 30.00ms (1.39%), Blocked: 0.00ns (0.00%), Output: 24 rows (120B)\n",
      "    │   Input avg.: 4442.67 rows, Input std.dev.: 105.05%\n",
      "    │   max_0 := max(price)\n",
      "    └─ ScanFilterProject[table = lakekeeper:housing.staging_prices$data@5103898280002112555, filterPredicate = (county = varchar 'WORCESTERSHIRE')]\n",
      "           Layout: [price:integer]\n",
      "           Estimates: {rows: 10030835 (47.83MB), cpu: 107.30M, memory: 0B, network: 0B}/{rows: 5015418 (23.92MB), cpu: 107.30M, memory: 0B, network: 0B}/{rows: 5015418 (23.92MB), cpu: 23.92M, memory: 0B, network: 0B}\n",
      "           CPU: 628.00ms (97.97%), Scheduled: 2.13s (98.38%), Blocked: 0.00ns (0.00%), Output: 106624 rows (520.63kB)\n",
      "           Input avg.: 417072.96 rows, Input std.dev.: 104.59%\n",
      "           county := 14:county:varchar\n",
      "           price := 2:price:integer\n",
      "           Input: 10009751 rows (81.81MB), Filtered: 98.93%, Physical input: 40.92MB, Physical input time: 765.49ms, Splits: 24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No partition on 'county'\n",
    "print(\n",
    "    pl.read_database(\n",
    "        \"EXPLAIN ANALYZE SELECT max(price) as max_price from housing.staging_prices where county = 'WORCESTERSHIRE'\",\n",
    "        engine,\n",
    "    ).item(0, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a852e4-7f76-4921-b90f-edc0dab51eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trino version: 475\n",
      "Queued: 317.52us, Analysis: 55.28ms, Planning: 41.79ms, Execution: 268.97ms\n",
      "Fragment 1 [SINGLE]\n",
      "    CPU: 3.77ms, Scheduled: 5.93ms, Blocked 467.57ms (Input: 367.50ms, Output: 0.00ns), Input: 22 rows (110B); per task: avg.: 22.00 std.dev.: 0.00, Output: 1 row (5B)\n",
      "    Peak Memory: 304B, Tasks count: 1; per task: max: 328B\n",
      "    Output layout: [max]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = FINAL]\n",
      "    │   Layout: [max:integer]\n",
      "    │   Estimates: {rows: 1 (5B), cpu: 40.13M, memory: 5B, network: 0B}\n",
      "    │   CPU: 1.00ms (0.48%), Scheduled: 1.00ms (0.15%), Blocked: 0.00ns (0.00%), Output: 1 row (5B)\n",
      "    │   Input avg.: 22.00 rows, Input std.dev.: 0.00%\n",
      "    │   max := max(max_0)\n",
      "    └─ LocalExchange[partitioning = SINGLE]\n",
      "       │   Layout: [max_0:integer]\n",
      "       │   Estimates: {rows: 8415759 (40.13MB), cpu: 0, memory: 0B, network: 0B}\n",
      "       │   CPU: 0.00ns (0.00%), Scheduled: 0.00ns (0.00%), Blocked: 97.00ms (20.86%), Output: 22 rows (110B)\n",
      "       │   Input avg.: 5.50 rows, Input std.dev.: 77.67%\n",
      "       └─ RemoteSource[sourceFragmentIds = [2]]\n",
      "              Layout: [max_0:integer]\n",
      "              CPU: 1.00ms (0.48%), Scheduled: 2.00ms (0.29%), Blocked: 368.00ms (79.14%), Output: 22 rows (110B)\n",
      "              Input avg.: 5.50 rows, Input std.dev.: 77.67%\n",
      "\n",
      "Fragment 2 [SOURCE]\n",
      "    CPU: 210.06ms, Scheduled: 682.74ms, Blocked 0.00ns (Input: 0.00ns, Output: 0.00ns), Input: 8415759 rows (40.13MB); per task: avg.: 8415759.00 std.dev.: 0.00, Output: 22 rows (110B)\n",
      "    Peak Memory: 10.98MB, Tasks count: 1; per task: max: 10.98MB\n",
      "    Total split distribution time: 14.72ms\n",
      "    Output layout: [max_0]\n",
      "    Output partitioning: SINGLE []\n",
      "    Aggregate[type = PARTIAL]\n",
      "    │   Layout: [max_0:integer]\n",
      "    │   Estimates: {rows: 8415759 (40.13MB), cpu: ?, memory: ?, network: ?}\n",
      "    │   CPU: 28.00ms (13.33%), Scheduled: 41.00ms (5.99%), Blocked: 0.00ns (0.00%), Output: 22 rows (110B)\n",
      "    │   Input avg.: 382534.50 rows, Input std.dev.: 114.42%\n",
      "    │   max_0 := max(price)\n",
      "    └─ TableScan[table = lakekeeper:housing.staging_prices$data@5103898280002112555 constraint on [date_of_transfer]]\n",
      "           Layout: [price:integer]\n",
      "           Estimates: {rows: 8415759 (40.13MB), cpu: 40.13M, memory: 0B, network: 0B}\n",
      "           CPU: 180.00ms (85.71%), Scheduled: 640.00ms (93.57%), Blocked: 0.00ns (0.00%), Output: 8415759 rows (40.13MB)\n",
      "           Input avg.: 382534.50 rows, Input std.dev.: 114.42%\n",
      "           price := 2:price:integer\n",
      "           3:date_of_transfer:date\n",
      "               :: [[2015-01-01, 2022-12-31]]\n",
      "           Input: 8415759 rows (40.13MB), Physical input: 34.05MB, Physical input time: 357.42ms, Splits: 22\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Partition on 'date_of_transfer'\n",
    "print(\n",
    "    pl.read_database(\n",
    "        \"EXPLAIN ANALYZE SELECT max(price) as max_price from housing.staging_prices where date_of_transfer between DATE '2015-01-01' AND DATE '2022-12-31'\",\n",
    "        engine,\n",
    "    ).item(0, 0)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
